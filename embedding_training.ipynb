{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. COVID-19 graph embedding alone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.modules import Module\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.utils import add_remaining_self_loops, add_self_loops\n",
    "from torch_geometric.utils import to_undirected\n",
    "from torch_geometric.nn import GCNConv, SAGEConv,GAE, VGAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='data/'\n",
    "exp_id='v0'\n",
    "device_id='cpu' #'cpu' if CPU, device number if GPU\n",
    "embedding_size=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load preprocessed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=pickle.load(open(data_path+'LabelEncoder_'+exp_id+'.pkl', 'rb'))\n",
    "edge_index=pickle.load(open(data_path+'edge_index_'+exp_id+'.pkl','rb'))\n",
    "node_feature_alone_np=pickle.load(open(data_path+'dirichlet_node_feature_'+exp_id+'.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feature_alone=torch.tensor(node_feature_alone_np, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge=torch.tensor(edge_index[['node1', 'node2']].values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_attr_dict={'gene-drug':0,'gene-gene':1,'bait-gene':2, 'gene-phenotype':3, 'drug-phenotype':4}\n",
    "edge_index['type']=edge_index['type'].apply(lambda x: edge_attr_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    27590\n",
       "1     5971\n",
       "3     1618\n",
       "4     1338\n",
       "2      247\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_attr=torch.tensor(edge_index['type'].values,dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(x=node_feature_alone,\n",
    "            edge_index=edge.t().contiguous(),\n",
    "            edge_attr=edge_attr\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 15444, 36764)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_features, data.num_nodes,data.num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/puzhouwang/opt/anaconda3/envs/drg/lib/python3.7/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'contains_isolated_nodes' is deprecated, use 'has_isolated_nodes' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.contains_isolated_nodes(), data.is_directed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_edges(data, val_ratio=0.05, test_ratio=0.1):\n",
    "    r\"\"\"Splits the edges of a :obj:`torch_geometric.data.Data` object\n",
    "    into positive and negative train/val/test edges, and adds attributes of\n",
    "    `train_pos_edge_index`, `train_neg_adj_mask`, `val_pos_edge_index`,\n",
    "    `val_neg_edge_index`, `test_pos_edge_index`, and `test_neg_edge_index`\n",
    "    to :attr:`data`.\n",
    "\n",
    "    Args:\n",
    "        data (Data): The data object.\n",
    "        val_ratio (float, optional): The ratio of positive validation\n",
    "            edges. (default: :obj:`0.05`)\n",
    "        test_ratio (float, optional): The ratio of positive test\n",
    "            edges. (default: :obj:`0.1`)\n",
    "\n",
    "    :rtype: :class:`torch_geometric.data.Data`\n",
    "    \"\"\"\n",
    "\n",
    "    assert 'batch' not in data  # No batch-mode.\n",
    "\n",
    "    num_nodes = data.num_nodes\n",
    "    row, col = data.edge_index\n",
    "    #data.edge_index = None\n",
    "    attr = data.edge_attr\n",
    "\n",
    "    # Return upper triangular portion.\n",
    "    #mask = row < col\n",
    "    #row, col = row[mask], col[mask]\n",
    "\n",
    "    n_v = int(math.floor(val_ratio * row.size(0)))\n",
    "    n_t = int(math.floor(test_ratio * row.size(0)))\n",
    "\n",
    "    # Positive edges.\n",
    "    perm = torch.randperm(row.size(0))\n",
    "    row, col = row[perm], col[perm]\n",
    "    attr=attr[perm]\n",
    "\n",
    "    r, c = row[:n_v], col[:n_v]\n",
    "    data.val_pos_edge_index = torch.stack([r, c], dim=0)\n",
    "    data.val_pos_edge_attr = attr[:n_v]\n",
    "    \n",
    "    r, c = row[n_v:n_v + n_t], col[n_v:n_v + n_t]\n",
    "    data.test_pos_edge_index = torch.stack([r, c], dim=0)\n",
    "    data.test_post_edge_attr = attr[n_v:n_v + n_t]\n",
    "\n",
    "    r, c = row[n_v + n_t:], col[n_v + n_t:]\n",
    "    data.train_pos_edge_index = torch.stack([r, c], dim=0)\n",
    "    data.train_pos_edge_attr = attr[n_v+n_t:]\n",
    "\n",
    "    # Negative edges.\n",
    "    neg_adj_mask = torch.ones(num_nodes, num_nodes, dtype=torch.uint8)\n",
    "    neg_adj_mask = neg_adj_mask.triu(diagonal=1).to(torch.bool)\n",
    "    neg_adj_mask[row, col] = 0\n",
    "\n",
    "    neg_row, neg_col = neg_adj_mask.nonzero().t()\n",
    "    perm = random.sample(range(neg_row.size(0)),\n",
    "                         min(n_v + n_t, neg_row.size(0)))\n",
    "    perm = torch.tensor(perm)\n",
    "    perm = perm.to(torch.long)\n",
    "    neg_row, neg_col = neg_row[perm], neg_col[perm]\n",
    "\n",
    "    neg_adj_mask[neg_row, neg_col] = 0\n",
    "    data.train_neg_adj_mask = neg_adj_mask\n",
    "\n",
    "    row, col = neg_row[:n_v], neg_col[:n_v]\n",
    "    data.val_neg_edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "    row, col = neg_row[n_v:n_v + n_t], neg_col[n_v:n_v + n_t]\n",
    "    data.test_neg_edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split=train_test_split_edges(data, test_ratio=0.1, val_ratio=0)\n",
    "x, train_pos_edge_index, train_pos_edge_attr = data_split.x.to(device), \\\n",
    "    data_split.train_pos_edge_index.to(device), data_split.train_pos_edge_attr.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_edge_index, train_pos_edge_attr=add_remaining_self_loops(train_pos_edge_index,train_pos_edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24838\n",
       "1    20755\n",
       "3     1460\n",
       "4     1205\n",
       "2      221\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(train_pos_edge_attr.cpu().numpy()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,train_pos_edge_index,train_pos_edge_attr = Variable(x),Variable(train_pos_edge_index),Variable(train_pos_edge_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define VGAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_VGAE(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, isClassificationTask=False):\n",
    "        super(Encoder_VGAE, self).__init__()\n",
    "        self.isClassificationTask=isClassificationTask\n",
    "        self.conv_gene_drug=  SAGEConv(in_channels, 2*out_channels, )\n",
    "        self.conv_gene_gene = SAGEConv(in_channels, 2*out_channels, )\n",
    "        self.conv_bait_gene = SAGEConv(in_channels, 2*out_channels, )\n",
    "        self.conv_gene_phenotype = SAGEConv(in_channels, 2*out_channels, )\n",
    "        self.conv_drug_phenotype = SAGEConv(in_channels, 2*out_channels)\n",
    "\n",
    "        self.bn = nn.BatchNorm1d(5*2*out_channels)\n",
    "        #variational encoder\n",
    "        self.conv_mu = SAGEConv(5*2*out_channels, out_channels, )\n",
    "        self.conv_logvar = SAGEConv(5*2*out_channels, out_channels,)\n",
    "\n",
    "    def forward(self,x,edge_index,edge_attr):\n",
    "        \n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        index_gene_drug=(edge_attr==0).nonzero().reshape(1,-1)[0]\n",
    "        edge_index_gene_drug=edge_index[:, index_gene_drug]\n",
    "        \n",
    "        index_gene_gene=(edge_attr==1).nonzero().reshape(1,-1)[0]\n",
    "        edge_index_gene_gene=edge_index[:, index_gene_gene]\n",
    "        \n",
    "        index_bait_gene=(edge_attr==2).nonzero().reshape(1,-1)[0]\n",
    "        edge_index_bait_gene=edge_index[:, index_bait_gene]\n",
    "        \n",
    "        index_gene_phenotype=(edge_attr==3).nonzero().reshape(1,-1)[0]\n",
    "        edge_index_gene_phenotype=edge_index[:, index_gene_phenotype]\n",
    "        \n",
    "        index_drug_phenotype=(edge_attr==4).nonzero().reshape(1,-1)[0]\n",
    "        edge_index_drug_phenotype=edge_index[:, index_drug_phenotype]\n",
    "        \n",
    "        \n",
    "        x_gene_drug = F.dropout(F.relu(self.conv_gene_drug(x,edge_index_gene_drug)), p=0.5, training=self.training, )\n",
    "        x_gene_gene = F.dropout(F.relu(self.conv_gene_gene(x,edge_index_gene_gene)), p=0.5, training=self.training)\n",
    "        x_bait_gene = F.dropout(F.relu(self.conv_bait_gene(x,edge_index_bait_gene)), p=0.1, training=self.training)\n",
    "        x_gene_phenotype = F.dropout(F.relu(self.conv_gene_phenotype(x,edge_index_gene_phenotype)), training=self.training)\n",
    "        x_drug_phenotype = F.dropout(F.relu(self.conv_drug_phenotype(x,edge_index_drug_phenotype)), training=self.training)\n",
    "\n",
    "        x=self.bn(torch.cat([x_gene_drug,x_gene_gene,x_bait_gene,x_gene_phenotype,x_drug_phenotype],dim=1))        \n",
    "        \n",
    "        return self.conv_mu(x,edge_index), self.conv_logvar(x,edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=VGAE(Encoder_VGAE(node_feature_alone.shape[1], embedding_size)).to(device)\n",
    "optimizer=torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x, train_pos_edge_index, train_pos_edge_attr)\n",
    "    loss = model.recon_loss(z, train_pos_edge_index)\n",
    "    loss = loss + (1 / data.num_nodes) * model.kl_loss()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss.item())\n",
    "    \n",
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z=model.encode(x, train_pos_edge_index,train_pos_edge_attr)\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.35942201036988447, 0.4050600513856305)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline\n",
    "model.test(x,data_split.test_pos_edge_index, data_split.test_neg_edge_index )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.621352195739746\n",
      "Epoch: 001, AUC: 0.5389, AP: 0.5028\n",
      "14.286808967590332\n",
      "Epoch: 002, AUC: 0.5734, AP: 0.5276\n",
      "13.90215015411377\n",
      "Epoch: 003, AUC: 0.6072, AP: 0.5535\n",
      "13.445852279663086\n",
      "Epoch: 004, AUC: 0.6328, AP: 0.5716\n",
      "13.195359230041504\n",
      "Epoch: 005, AUC: 0.6706, AP: 0.6131\n",
      "12.844427108764648\n",
      "Epoch: 006, AUC: 0.6965, AP: 0.6473\n",
      "12.30419921875\n",
      "Epoch: 007, AUC: 0.7252, AP: 0.7003\n",
      "11.705829620361328\n",
      "Epoch: 008, AUC: 0.7405, AP: 0.7326\n",
      "11.174623489379883\n",
      "Epoch: 009, AUC: 0.7537, AP: 0.7623\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train()\n",
    "    auc, ap = test(data_split.test_pos_edge_index, data_split.test_neg_edge_index)\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "z=model.encode(x, data.edge_index.to(device), data.edge_attr.to(device))\n",
    "z_np = z.squeeze().detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the new embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(z_np, open(data_path+'COVID_embedding_'+exp_id+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), data_path+'COVID_VAE_encoders_'+exp_id+'.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Hybrid Embedding: COVID-19 graph + DRKG pre-train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. embedding dimension: 128 (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "node_feature_np=pickle.load(open(data_path+'node_feature_'+exp_id+'.pkl','rb'))\n",
    "node_feature=torch.tensor(node_feature_np, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(x=node_feature,\n",
    "            edge_index=edge.t().contiguous(),\n",
    "            edge_attr=edge_attr\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split=train_test_split_edges(data, test_ratio=0.1, val_ratio=0)\n",
    "x, train_pos_edge_index, train_pos_edge_attr = data_split.x.to(device), \\\n",
    "    data_split.train_pos_edge_index.to(device), data_split.train_pos_edge_attr.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_edge_index, train_pos_edge_attr=add_remaining_self_loops(train_pos_edge_index,train_pos_edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,train_pos_edge_index,train_pos_edge_attr = Variable(x),Variable(train_pos_edge_index),Variable(train_pos_edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=VGAE(Encoder_VGAE(node_feature.shape[1], embedding_size)).to(device)\n",
    "optimizer=torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.35835666399466704, 0.473765308861948)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DRKG's accuracy for comparison\n",
    "model.test(x,data_split.test_pos_edge_index, data_split.test_neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.6003360748291\n",
      "Epoch: 001, AUC: 0.6386, AP: 0.5786\n",
      "17.687053680419922\n",
      "Epoch: 002, AUC: 0.6800, AP: 0.5970\n",
      "16.505571365356445\n",
      "Epoch: 003, AUC: 0.6984, AP: 0.6072\n",
      "16.146207809448242\n",
      "Epoch: 004, AUC: 0.7155, AP: 0.6272\n",
      "16.748153686523438\n",
      "Epoch: 005, AUC: 0.7362, AP: 0.6656\n",
      "16.870141983032227\n",
      "Epoch: 006, AUC: 0.7481, AP: 0.6815\n",
      "16.659015655517578\n",
      "Epoch: 007, AUC: 0.7700, AP: 0.7054\n",
      "16.335309982299805\n",
      "Epoch: 008, AUC: 0.7942, AP: 0.7402\n",
      "15.86346435546875\n",
      "Epoch: 009, AUC: 0.7977, AP: 0.7399\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train()\n",
    "    auc, ap = test(data_split.test_pos_edge_index, data_split.test_neg_edge_index)\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "z=model.encode(x, data.edge_index.to(device), data.edge_attr.to(device))\n",
    "z_np = z.squeeze().detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(z_np, open(data_path+f'hybrid_embedding_{embedding_size}_'+exp_id+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), data_path+f'hybrid_VAE_encoders_{embedding_size}_'+exp_id+'.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. embedding dimension: 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 64\n",
    "model=VGAE(Encoder_VGAE(node_feature.shape[1], embedding_size)).to(device)\n",
    "optimizer=torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.35835666399466704, 0.473765308861948)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DRKG's accuracy for comparison\n",
    "model.test(x,data_split.test_pos_edge_index, data_split.test_neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.738143920898438\n",
      "Epoch: 001, AUC: 0.6779, AP: 0.6313\n",
      "14.36874008178711\n",
      "Epoch: 002, AUC: 0.7193, AP: 0.7028\n",
      "13.348702430725098\n",
      "Epoch: 003, AUC: 0.7569, AP: 0.7800\n",
      "12.40897274017334\n",
      "Epoch: 004, AUC: 0.7787, AP: 0.8067\n",
      "12.35556697845459\n",
      "Epoch: 005, AUC: 0.7993, AP: 0.8266\n",
      "11.076025009155273\n",
      "Epoch: 006, AUC: 0.8133, AP: 0.8369\n",
      "10.4027099609375\n",
      "Epoch: 007, AUC: 0.8073, AP: 0.8198\n",
      "9.729873657226562\n",
      "Epoch: 008, AUC: 0.7676, AP: 0.7744\n",
      "9.39797306060791\n",
      "Epoch: 009, AUC: 0.7551, AP: 0.7595\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train()\n",
    "    auc, ap = test(data_split.test_pos_edge_index, data_split.test_neg_edge_index)\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "z=model.encode(x, data.edge_index.to(device), data.edge_attr.to(device))\n",
    "z_np = z.squeeze().detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(z_np, open(data_path+f'hybrid_embedding_{embedding_size}_'+exp_id+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), data_path+f'hybrid_VAE_encoders_{embedding_size}_'+exp_id+'.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. embedding dimension: 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 256\n",
    "model=VGAE(Encoder_VGAE(node_feature.shape[1], embedding_size)).to(device)\n",
    "optimizer=torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3765956514686327, 0.4823402969907613)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DRKG's accuracy for comparison\n",
    "model.test(x,data_split.test_pos_edge_index, data_split.test_neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.637834548950195\n",
      "Epoch: 001, AUC: 0.5987, AP: 0.5107\n",
      "18.98118782043457\n",
      "Epoch: 002, AUC: 0.6702, AP: 0.6053\n",
      "18.94562339782715\n",
      "Epoch: 003, AUC: 0.6729, AP: 0.6091\n",
      "19.052785873413086\n",
      "Epoch: 004, AUC: 0.6692, AP: 0.6064\n",
      "19.239566802978516\n",
      "Epoch: 005, AUC: 0.6709, AP: 0.6080\n",
      "18.930299758911133\n",
      "Epoch: 006, AUC: 0.6842, AP: 0.6191\n",
      "18.367544174194336\n",
      "Epoch: 007, AUC: 0.7063, AP: 0.6377\n",
      "17.764646530151367\n",
      "Epoch: 008, AUC: 0.7266, AP: 0.6554\n",
      "17.29031753540039\n",
      "Epoch: 009, AUC: 0.7442, AP: 0.6719\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train()\n",
    "    auc, ap = test(data_split.test_pos_edge_index, data_split.test_neg_edge_index)\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "z=model.encode(x, data.edge_index.to(device), data.edge_attr.to(device))\n",
    "z_np = z.squeeze().detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(z_np, open(data_path+f'hybrid_embedding_{embedding_size}_'+exp_id+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), data_path+f'hybrid_VAE_encoders_{embedding_size}_'+exp_id+'.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. default embedding size (128) without bait-prey information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = pickle.load(open(data_path+'edge_index_no_bp_'+exp_id+'.pkl','rb'))\n",
    "node_feature_no_bp_np = pickle.load(open(data_path+'node_feature_no_bp_'+exp_id+'.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feature_no_bp = torch.tensor(node_feature_no_bp_np, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge=torch.tensor(edge_index[['node1', 'node2']].values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_attr_dict={'gene-drug':0,'gene-gene':1,'gene-phenotype':3, 'drug-phenotype':4}\n",
    "edge_index['type']=edge_index['type'].apply(lambda x: edge_attr_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    27590\n",
       "1     5971\n",
       "3     1618\n",
       "4     1338\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_attr=torch.tensor(edge_index['type'].values,dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(x=node_feature_no_bp,\n",
    "            edge_index=edge.t().contiguous(),\n",
    "            edge_attr=edge_attr\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 15444, 36517)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_features, data.num_nodes,data.num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split=train_test_split_edges(data, test_ratio=0.1, val_ratio=0)\n",
    "x, train_pos_edge_index, train_pos_edge_attr = data_split.x.to(device), \\\n",
    "    data_split.train_pos_edge_index.to(device), data_split.train_pos_edge_attr.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_edge_index, train_pos_edge_attr=add_remaining_self_loops(train_pos_edge_index,train_pos_edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,train_pos_edge_index,train_pos_edge_attr = Variable(x),Variable(train_pos_edge_index),Variable(train_pos_edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_VGAE_no_bp(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, isClassificationTask=False):\n",
    "        super(Encoder_VGAE_no_bp, self).__init__()\n",
    "        self.isClassificationTask=isClassificationTask\n",
    "        self.conv_gene_drug=  SAGEConv(in_channels, 2*out_channels, )\n",
    "        self.conv_gene_gene = SAGEConv(in_channels, 2*out_channels, )\n",
    "        self.conv_gene_phenotype = SAGEConv(in_channels, 2*out_channels, )\n",
    "        self.conv_drug_phenotype = SAGEConv(in_channels, 2*out_channels)\n",
    "\n",
    "        self.bn = nn.BatchNorm1d(4*2*out_channels)\n",
    "        #variational encoder\n",
    "        self.conv_mu = SAGEConv(4*2*out_channels, out_channels, )\n",
    "        self.conv_logvar = SAGEConv(4*2*out_channels, out_channels,)\n",
    "\n",
    "    def forward(self,x,edge_index,edge_attr):\n",
    "        \n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        index_gene_drug=(edge_attr==0).nonzero().reshape(1,-1)[0]\n",
    "        edge_index_gene_drug=edge_index[:, index_gene_drug]\n",
    "        \n",
    "        index_gene_gene=(edge_attr==1).nonzero().reshape(1,-1)[0]\n",
    "        edge_index_gene_gene=edge_index[:, index_gene_gene]\n",
    "        \n",
    "        index_gene_phenotype=(edge_attr==3).nonzero().reshape(1,-1)[0]\n",
    "        edge_index_gene_phenotype=edge_index[:, index_gene_phenotype]\n",
    "        \n",
    "        index_drug_phenotype=(edge_attr==4).nonzero().reshape(1,-1)[0]\n",
    "        edge_index_drug_phenotype=edge_index[:, index_drug_phenotype]\n",
    "        \n",
    "        \n",
    "        x_gene_drug = F.dropout(F.relu(self.conv_gene_drug(x,edge_index_gene_drug)), p=0.5, training=self.training, )\n",
    "        x_gene_gene = F.dropout(F.relu(self.conv_gene_gene(x,edge_index_gene_gene)), p=0.5, training=self.training)\n",
    "        x_gene_phenotype = F.dropout(F.relu(self.conv_gene_phenotype(x,edge_index_gene_phenotype)), training=self.training)\n",
    "        x_drug_phenotype = F.dropout(F.relu(self.conv_drug_phenotype(x,edge_index_drug_phenotype)), training=self.training)\n",
    "\n",
    "        x=self.bn(torch.cat([x_gene_drug,x_gene_gene,x_gene_phenotype,x_drug_phenotype],dim=1))        \n",
    "        \n",
    "        return self.conv_mu(x,edge_index), self.conv_logvar(x,edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "model=VGAE(Encoder_VGAE_no_bp(node_feature.shape[1], embedding_size)).to(device)\n",
    "optimizer=torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.40109878609590643, 0.4553820212669144)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DRKG's accuracy for comparison\n",
    "model.test(x,data_split.test_pos_edge_index, data_split.test_neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.09906005859375\n",
      "Epoch: 001, AUC: 0.4841, AP: 0.4471\n",
      "18.170408248901367\n",
      "Epoch: 002, AUC: 0.5105, AP: 0.4581\n",
      "18.1473331451416\n",
      "Epoch: 003, AUC: 0.5472, AP: 0.4769\n",
      "17.576248168945312\n",
      "Epoch: 004, AUC: 0.5846, AP: 0.4984\n",
      "17.136661529541016\n",
      "Epoch: 005, AUC: 0.6121, AP: 0.5166\n",
      "15.71886157989502\n",
      "Epoch: 006, AUC: 0.6325, AP: 0.5338\n",
      "15.182626724243164\n",
      "Epoch: 007, AUC: 0.6502, AP: 0.5560\n",
      "14.717133522033691\n",
      "Epoch: 008, AUC: 0.6614, AP: 0.5829\n",
      "14.302988052368164\n",
      "Epoch: 009, AUC: 0.6656, AP: 0.6041\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train()\n",
    "    auc, ap = test(data_split.test_pos_edge_index, data_split.test_neg_edge_index)\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "z=model.encode(x, data.edge_index.to(device), data.edge_attr.to(device))\n",
    "z_np = z.squeeze().detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(z_np, open(data_path+f'hybrid_embedding_{embedding_size}_no_bp_'+exp_id+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), data_path+f'hybrid_VAE_encoders_{embedding_size}_no_bp_'+exp_id+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drg",
   "language": "python",
   "name": "drg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
